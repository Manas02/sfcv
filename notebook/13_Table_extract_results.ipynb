{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step Forward Cross Validation for Bioactivity Prediction",
   "id": "c2e380d4b5a2960d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a table extracting relevant information from the benchmark results",
   "id": "b80107d3bdacb6bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm"
   ],
   "id": "8038347753c45421",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "NOVELTY_TC = 0.55\n",
    "data_dir = \"../benchmark/data/results\"\n",
    "fnames = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "results = []\n",
    "\n",
    "for fname in tqdm(fnames):\n",
    "    df = pd.read_csv(fname)\n",
    "    pred_cols = [i for i in df.columns if i.endswith(\"_regressor_factory\")]\n",
    "    target = os.path.basename(fname).replace(\".csv\", \"\")\n",
    "    if target == \"target_CHEMBL240\":\n",
    "        discovery_func = lambda d: d[\"pchembl_value\"] < 5.2\n",
    "    else:\n",
    "        discovery_func = lambda d: d[\"pchembl_value\"] > 7\n",
    "\n",
    "    split_cache = {}\n",
    "    for pred_col in pred_cols:\n",
    "        match = re.search(r\"(.*?)_Fold_(\\d+)_(.*?)_(.*?)_regressor_factory\", pred_col)\n",
    "        split_type, fold_no, fp, model = match.groups()\n",
    "        split_key = f\"{split_type}_Fold_{fold_no}\"\n",
    "\n",
    "        if split_key in split_cache:\n",
    "            df_test, df_train = split_cache[split_key]\n",
    "        else:\n",
    "            mask_test = df[split_key] == \"Test\"\n",
    "            mask_train = df[split_key] == \"Train\"\n",
    "            df_test = df[mask_test]\n",
    "            df_train = df[mask_train]\n",
    "            split_cache[split_key] = (df_test, df_train)\n",
    "\n",
    "        n_test = df_test.shape[0]\n",
    "        n_train = df_train.shape[0]\n",
    "\n",
    "        novelty_col = f\"{split_type}_Fold_{fold_no}_{fp}_Tc\"\n",
    "        novelty_mask = df_test[novelty_col] < NOVELTY_TC\n",
    "\n",
    "        discovery_mask = discovery_func(df_test)\n",
    "        total_discovery = discovery_mask.sum()\n",
    "\n",
    "        novel_discovery_mask = novelty_mask & discovery_mask\n",
    "        n_novel = novelty_mask.sum()\n",
    "\n",
    "        err_mask = (np.abs(df_test[pred_col] - df_test[\"pchembl_value\"]) <= 0.5)\n",
    "\n",
    "        novel_disc_within_err = (novel_discovery_mask & err_mask).sum()\n",
    "        disc_within_err = (discovery_mask & err_mask).sum()\n",
    "\n",
    "        y_true = df_test[\"pchembl_value\"].values\n",
    "        y_pred = df_test[pred_col].values\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        rmse = root_mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        if novelty_mask.sum() > 0:\n",
    "            novelty_err = mean_absolute_error(\n",
    "                df_test.loc[novelty_mask, \"pchembl_value\"],\n",
    "                df_test.loc[novelty_mask, pred_col]\n",
    "            )\n",
    "        else:\n",
    "            novelty_err = np.nan\n",
    "\n",
    "        discovery_yield = disc_within_err / total_discovery if total_discovery > 0 else 0\n",
    "\n",
    "        results.append({\n",
    "            \"target\": target,\n",
    "            \"split_type\": split_type,\n",
    "            \"fold_no\": fold_no,\n",
    "            \"fingerprint\": fp,\n",
    "            \"model\": model,\n",
    "            \"r2\": r2,\n",
    "            \"rmse\": rmse,\n",
    "            \"novelty_err\": novelty_err,\n",
    "            \"discovery_yield\": discovery_yield,\n",
    "            \"number of discovery compounds\": total_discovery,\n",
    "            \"number of discovery compounds within error range\": disc_within_err,\n",
    "            \"number of novel compounds\": n_novel,\n",
    "            \"number of novel discovery compounds\": novel_discovery_mask.sum(),\n",
    "            \"number of novel discovery compounds within error range\": novel_disc_within_err,\n",
    "            \"number of test compounds\": n_test,\n",
    "            \"number of train compounds\": n_train,\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"../benchmark/results/tables/results.csv\", index=False)"
   ],
   "id": "12c6e0cb0208ddc1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
