{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c8e543c87c1a68",
   "metadata": {},
   "source": [
    "# Step Forward Cross Validation for Bioactivity Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900264e7e991986",
   "metadata": {},
   "source": [
    "## Benchmark for hERG, MAP14K and VEGFR2 for 3 fingerprints (ECFP4, RDKit and AtomPair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f4364bdfd376c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sfcv import SortedStepForwardCV, UnsortedStepForwardCV, ScaffoldSplitCV, RandomSplitCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61fadc6eb4b3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aea998be6b674d",
   "metadata": {},
   "source": [
    "### Fingerprint Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29840a4d33a55703",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecfp4gen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "rdkgen = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=2048)\n",
    "apgen = rdFingerprintGenerator.GetAtomPairGenerator(fpSize=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c329f27454b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ecfp4(smiles: str) -> np.ndarray | None:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return ecfp4gen.GetFingerprintAsNumPy(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98e735a66f7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rdkit_fp(smiles: str) -> np.ndarray | None:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return rdkgen.GetFingerprintAsNumPy(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f861157f69670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_atompair_fp(smiles: str) -> np.ndarray | None:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return apgen.GetFingerprintAsNumPy(mol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d7e2b4b765aecc",
   "metadata": {},
   "source": [
    "#### Since, we'll be training on these fingerprints, precomputing these fingerprints and saving them will save some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750050089abe2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_set = set()\n",
    "\n",
    "for fname in os.listdir(\"../benchmark/data/processed\"):\n",
    "    if fname.endswith(\".csv\"):\n",
    "        df = pd.read_csv(f\"../benchmark/data/processed/{fname}\")\n",
    "        molecule_set |= set(df[\"standardized_smiles\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2aa857b085bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(molecule_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f415822a67fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "smi2ecfp4 = {}\n",
    "smi2atompair = {}\n",
    "smi2rdkit = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca791ea208541dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for smi in tqdm(molecule_set, desc=\"Computing Fingerprints\"):\n",
    "    smi2ecfp4[smi] = compute_ecfp4(smi)\n",
    "    smi2atompair[smi] = compute_atompair_fp(smi)\n",
    "    smi2rdkit[smi] = compute_rdkit_fp(smi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a57ce43013cc02",
   "metadata": {},
   "source": [
    "## Saving the split columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d595ae9b29a0f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../benchmark/data/final/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dba944a056ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitters = {\n",
    "    \"RandomSplit\": RandomSplitCV(frac_train=0.9, n_folds=10, seed=69420),\n",
    "    \"ScaffoldSplit\": ScaffoldSplitCV(smiles_col='standardized_smiles', n_folds=10, frac_train=0.9, seed=69420,\n",
    "                                     include_chirality=False),\n",
    "    \"SortedStepForward_LogD\": SortedStepForwardCV(sorting_col=\"LogD\", ideal=2, n_bins=10, ascending=False),\n",
    "    \"SortedStepForward_LogP\": SortedStepForwardCV(sorting_col=\"LogP\", ideal=2, n_bins=10, ascending=False),\n",
    "    \"SortedStepForward_MCE18\": SortedStepForwardCV(sorting_col=\"MCE18\", n_bins=10, ascending=True),\n",
    "    \"UnsortedStepForward\": UnsortedStepForwardCV(n_bins=10, random_state=69420)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55007472b30cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cv_split_columns(df, cv_splitters):\n",
    "    df = df.copy()\n",
    "    for split_name, cv_splitter in cv_splitters.items():\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(cv_splitter.split(df), start=1):\n",
    "            col_name = f\"{split_name}_Fold_{fold_idx}\"\n",
    "            df[col_name] = None\n",
    "            df.loc[train_idx, col_name] = \"Train\"\n",
    "            df.loc[test_idx, col_name] = \"Test\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec778f5f3aa177",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in tqdm(os.listdir('../benchmark/data/processed/'), desc=\"Processing Splits\"):\n",
    "    if os.path.exists(f\"../benchmark/data/final/{fname}\"):\n",
    "        continue\n",
    "    if fname.endswith('.csv'):\n",
    "        df = pd.read_csv(f\"../benchmark/data/processed/{fname}\")\n",
    "        df = add_cv_split_columns(df, cv_splitters)\n",
    "        df.to_csv(f\"../benchmark/data/final/{fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ab2ef4afb0850",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef98085dec51d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_regressor_factory(n_train, random_state=42):\n",
    "    n_hidden = min(25, int(np.sqrt(n_train)))\n",
    "    return MLPRegressor(\n",
    "        hidden_layer_sizes=(n_hidden,), random_state=random_state, max_iter=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db7cab51faf3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_regressor_factory(n_train, random_state=42):\n",
    "    n_estimators = min(25, int(np.sqrt(n_train)))\n",
    "    return XGBRegressor(n_estimators=n_estimators, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4713c108ce5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_regressor_factory(n_train, random_state=42):\n",
    "    n_trees = min(25, int(np.sqrt(n_train)))\n",
    "    return RandomForestRegressor(n_estimators=n_trees, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7dcfd888f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_factories = [rf_regressor_factory, xgb_regressor_factory, mlp_regressor_factory]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8f3a3207668605",
   "metadata": {},
   "source": [
    "## Bulk Tanimoto Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39974d081dec8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_tanimoto_similarity(mol_fp: np.ndarray, list_of_fps: np.ndarray) -> np.ndarray:\n",
    "    intersection = np.sum(list_of_fps & mol_fp, axis=1)\n",
    "    union = np.sum(list_of_fps | mol_fp, axis=1)\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfbdde1557ade7f",
   "metadata": {},
   "source": [
    "## Let's Compute the Max Tanimoto Similarity for Test compounds with Train Compounds for each split and fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbe6e5eed635b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../benchmark/data/novelty/\", exist_ok=True)\n",
    "os.makedirs(\"../benchmark/data/results/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3097c8a0a5636ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp2map = {\"ECFP4\": smi2ecfp4,\n",
    "          \"RDKitFP\": smi2rdkit,\n",
    "          \"AtomPairsFP\": smi2atompair}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c032f71d62fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in tqdm(os.listdir('../benchmark/data/final/'), desc=\"Processing Bulk Tanimoto Similarity\"):\n",
    "    if not fname.endswith('.csv'):\n",
    "        continue\n",
    "\n",
    "    if os.path.exists(f\"../benchmark/data/novelty/{fname}\"):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(f\"../benchmark/data/final/{fname}\")\n",
    "    fold_cols = [col for col in df.columns if \"_Fold_\" in col]\n",
    "    new_columns = {}\n",
    "    for fp_name, fp_dict in fp2map.items():\n",
    "        X_full = np.vstack(df['standardized_smiles'].map(fp_dict).values)\n",
    "\n",
    "        for fold_col in fold_cols:\n",
    "            train_mask = (df[fold_col] == \"Train\").values\n",
    "            test_mask = (df[fold_col] == \"Test\").values\n",
    "\n",
    "            X_train = X_full[train_mask]\n",
    "            X_test = X_full[test_mask]\n",
    "\n",
    "            max_tcs = [bulk_tanimoto_similarity(test_fp, X_train).max() for test_fp in X_test]\n",
    "            new_columns[f\"{fold_col}_{fp_name}_Tc\"] = pd.Series(data=max_tcs, index=df.index[test_mask])\n",
    "\n",
    "    if new_columns:\n",
    "        new_cols_df = pd.DataFrame(new_columns, index=df.index)\n",
    "        df = pd.concat([df, new_cols_df], axis=1)\n",
    "        df.to_csv(f\"../benchmark/data/novelty/{fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968afab74470b0a",
   "metadata": {},
   "source": [
    "### Now that we can calculate the novelty metrics, let's focus on the model benchmark.\n",
    "\n",
    "```\n",
    "For each Target:\n",
    "    For each Fingerprint:\n",
    "        X <- compute_fp(SMILES, Fingerprint)\n",
    "        For each Split:\n",
    "            For each Fold:\n",
    "                X_train <- X\n",
    "                y_train <- y\n",
    "                train_model(X_train, y_train)\n",
    "                predict_all(X)\n",
    "                save_predictions_as_col()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73845f105f9416f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_regressor(regressor_factory, X_train, y_train, fingerprint_vals):\n",
    "    regressor = regressor_factory(len(X_train))\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(np.vstack(fingerprint_vals))\n",
    "    identifier = getattr(regressor_factory, '__name__', str(regressor_factory))\n",
    "    return identifier, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4249b0-2497-4bbd-afa6-27fa4a7c3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afacc6c9-4b5f-4f6f-967d-ce901bce0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_task(task):\n",
    "    fname, index, fold_col, fp_name, regressor_factory, X_train, y_train, X_full = task\n",
    "    model_name, preds = process_regressor(regressor_factory, X_train, y_train, X_full)\n",
    "    key = f\"{fold_col}_{fp_name}_{model_name}\"\n",
    "    return fname, key, preds, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b34fb-8c95-41bc-b67c-65a831286093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tasks = []\n",
    "\n",
    "for fname in tqdm(os.listdir('../benchmark/data/novelty/'), desc=\"Gathering Tasks\"):\n",
    "    if not fname.endswith('.csv'):\n",
    "        continue\n",
    "    if os.path.exists(f\"../benchmark/data/results/{fname}\"):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(f\"../benchmark/data/novelty/{fname}\")\n",
    "    fold_cols = [col for col in df.columns if (\"_Fold_\" in col and \"_Tc\" not in col)]\n",
    "\n",
    "    for fp_name, fp_dict in fp2map.items():\n",
    "        X_full = np.vstack(df['standardized_smiles'].map(fp_dict).values)\n",
    "\n",
    "        for fold_col in fold_cols:\n",
    "            train_mask = (df[fold_col] == \"Train\").values\n",
    "            X_train = X_full[train_mask]\n",
    "            y_train = df.loc[train_mask, \"pchembl_value\"].values\n",
    "\n",
    "            for regressor_factory in regressor_factories:\n",
    "                tasks.append((fname, df.index, fold_col, fp_name, regressor_factory, X_train, y_train, X_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766bf9b-50ed-4404-9091-d9e7d214bff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tqdm_joblib(tqdm(desc=\"Processing tasks\", total=len(tasks))):\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_task)(task) for task in tasks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d53f171-1996-4b24-a2b8-2cafa97bf9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_results = {}\n",
    "for fname, key, preds, index in results:\n",
    "    if fname not in file_results:\n",
    "        file_results[fname] = {}\n",
    "    file_results[fname][key] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ff734-aa61-4cff-a7c8-711299829b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname, new_columns in file_results.items():\n",
    "    df = pd.read_csv(f\"../benchmark/data/novelty/{fname}\", index_col=0)\n",
    "    new_cols_df = pd.DataFrame(new_columns, index=df.index)\n",
    "    df = pd.concat([df, new_cols_df], axis=1)\n",
    "    df.to_csv(f\"../benchmark/data/results/{fname}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
