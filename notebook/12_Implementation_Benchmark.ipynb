{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step Forward Cross Validation for Bioactivity Prediction",
   "id": "53c8e543c87c1a68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Benchmark for hERG, MAP14K and VEGFR2 for 3 fingerprints (ECFP4, RDKit and AtomPair)",
   "id": "a900264e7e991986"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../sfcv/')\n",
    "from datasplit import SortedStepForwardCV, UnsortedStepForwardCV, ScaffoldSplitCV, RandomSplitCV\n",
    "\n",
    "os.chdir('../notebook/')"
   ],
   "id": "61f4364bdfd376c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:14:38.677374Z",
     "start_time": "2025-02-18T18:14:38.670174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ],
   "id": "b61fadc6eb4b3692",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fingerprint Calculation",
   "id": "57aea998be6b674d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ecfp4gen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "rdkgen = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=2048)\n",
    "apgen = rdFingerprintGenerator.GetAtomPairGenerator(fpSize=2048)"
   ],
   "id": "29840a4d33a55703",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_ecfp4(smiles: str) -> np.ndarray | None:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return ecfp4gen.GetFingerprintAsNumPy(mol)"
   ],
   "id": "3f6c329f27454b22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_rdkit_fp(smiles: str) -> np.ndarray | None:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return rdkgen.GetFingerprintAsNumPy(mol)"
   ],
   "id": "2c98e735a66f7d38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_atompair_fp(smiles: str) -> np.ndarray | None:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return apgen.GetFingerprintAsNumPy(mol)"
   ],
   "id": "806f861157f69670",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Since, we'll be training on these fingerprints, precomputing these fingerprints and saving them will save some time.",
   "id": "67d7e2b4b765aecc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "molecule_set = set()\n",
    "\n",
    "for fname in os.listdir(\"../benchmark/data/processed\"):\n",
    "    if fname.endswith(\".csv\"):\n",
    "        df = pd.read_csv(f\"../benchmark/data/processed/{fname}\")\n",
    "        molecule_set |= set(df[\"standardized_smiles\"].unique())"
   ],
   "id": "750050089abe2302",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(molecule_set)",
   "id": "82f2aa857b085bb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "smi2ecfp4 = {}\n",
    "smi2atompair = {}\n",
    "smi2rdkit = {}"
   ],
   "id": "ce8f415822a67fba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for smi in tqdm(molecule_set, desc=\"Computing Fingerprints\"):\n",
    "    smi2ecfp4[smi] = compute_ecfp4(smi)\n",
    "    smi2atompair[smi] = compute_atompair_fp(smi)\n",
    "    smi2rdkit[smi] = compute_rdkit_fp(smi)"
   ],
   "id": "fca791ea208541dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving the split columns",
   "id": "96a57ce43013cc02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.makedirs(\"../benchmark/data/final/\", exist_ok=True)",
   "id": "d595ae9b29a0f554",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cv_splitters = {\n",
    "    \"RandomSplit\": RandomSplitCV(frac_train=0.9, n_folds=10, seed=69420),\n",
    "    \"ScaffoldSplit\": ScaffoldSplitCV(smiles_col='standardized_smiles', n_folds=10, frac_train=0.9, seed=69420,\n",
    "                                     include_chirality=False),\n",
    "    \"SortedStepForward_LogD\": SortedStepForwardCV(sorting_col=\"LogD\", ideal=2, n_bins=10, ascending=False),\n",
    "    \"SortedStepForward_LogP\": SortedStepForwardCV(sorting_col=\"LogP\", ideal=2, n_bins=10, ascending=False),\n",
    "    \"SortedStepForward_MCE18\": SortedStepForwardCV(sorting_col=\"MCE18\", n_bins=10, ascending=True),\n",
    "    \"UnsortedStepForward\": UnsortedStepForwardCV(n_bins=10, random_state=69420)\n",
    "}"
   ],
   "id": "41dba944a056ad2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def add_cv_split_columns(df, cv_splitters):\n",
    "    df = df.copy()\n",
    "    for split_name, cv_splitter in cv_splitters.items():\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(cv_splitter.split(df), start=1):\n",
    "            col_name = f\"{split_name}_Fold_{fold_idx}\"\n",
    "            df[col_name] = None\n",
    "            df.loc[train_idx, col_name] = \"Train\"\n",
    "            df.loc[test_idx, col_name] = \"Test\"\n",
    "    return df"
   ],
   "id": "4e55007472b30cda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for fname in tqdm(os.listdir('../benchmark/data/processed/'), desc=\"Processing Splits\"):\n",
    "    if os.path.exists(f\"../benchmark/data/final/{fname}\"):\n",
    "        continue\n",
    "    if fname.endswith('.csv'):\n",
    "        df = pd.read_csv(f\"../benchmark/data/processed/{fname}\")\n",
    "        df = add_cv_split_columns(df, cv_splitters)\n",
    "        df.to_csv(f\"../benchmark/data/final/{fname}\")"
   ],
   "id": "1dec778f5f3aa177",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Models",
   "id": "4b1ab2ef4afb0850"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def mlp_regressor_factory(n_train, random_state=42):\n",
    "    n_hidden = min(25, int(np.sqrt(n_train)))\n",
    "    return MLPRegressor(\n",
    "        hidden_layer_sizes=(n_hidden,), random_state=random_state, max_iter=1000\n",
    "    )"
   ],
   "id": "ef98085dec51d6b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def xgb_regressor_factory(n_train, random_state=42):\n",
    "    n_estimators = min(25, int(np.sqrt(n_train)))\n",
    "    return XGBRegressor(n_estimators=n_estimators, random_state=random_state)"
   ],
   "id": "1db7cab51faf3fe9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rf_regressor_factory(n_train, random_state=42):\n",
    "    n_trees = min(25, int(np.sqrt(n_train)))\n",
    "    return RandomForestRegressor(n_estimators=n_trees, random_state=random_state)"
   ],
   "id": "bd4713c108ce5883",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "regressor_factories = [rf_regressor_factory, xgb_regressor_factory, mlp_regressor_factory]",
   "id": "78b7dcfd888f2f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_regressor(regressor_factory, X_train, y_train, fingerprint_vals):\n",
    "    regressor = regressor_factory(len(X_train))\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(np.vstack(fingerprint_vals))\n",
    "    identifier = getattr(regressor_factory, '__name__', str(regressor_factory))\n",
    "    return identifier, y_pred"
   ],
   "id": "6587d538a0e4bec3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bulk Tanimoto Similarity",
   "id": "fe8f3a3207668605"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def bulk_tanimoto_similarity(mol_fp: np.ndarray, list_of_fps: np.ndarray) -> np.ndarray:\n",
    "    intersection = np.sum(list_of_fps & mol_fp, axis=1)\n",
    "    union = np.sum(list_of_fps | mol_fp, axis=1)\n",
    "    return intersection / union"
   ],
   "id": "f39974d081dec8c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Let's Train the models",
   "id": "7bfbdde1557ade7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.makedirs(\"../benchmark/data/results/\", exist_ok=True)",
   "id": "a1cbe6e5eed635b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:14:01.532851Z",
     "start_time": "2025-02-18T18:14:01.530163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fp2map = {\"ECFP4\": smi2ecfp4,\n",
    "          \"RDKitFP\": smi2rdkit,\n",
    "          \"AtomPairsFP\": smi2atompair}"
   ],
   "id": "3097c8a0a5636ac2",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:14:32.014533Z",
     "start_time": "2025-02-18T18:14:02.732663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for fname in tqdm(os.listdir(\"../benchmark/data/final/\"), desc=\"Training\"):\n",
    "    if fname.endswith(\".csv\"):\n",
    "        df = pd.read_csv(f\"../benchmark/data/final/{fname}\")\n",
    "\n",
    "        fold_cols = [i for i in df.columns if \"_Fold_\" in i]\n",
    "        for fold_col in tqdm(fold_cols, desc=\"Processing Splits and Folds\"):\n",
    "            test_mask = df[fold_col] == \"Test\"\n",
    "            train_mask = df[fold_col] == \"Train\"\n",
    "\n",
    "            for fp, mapping in fp2map.items():\n",
    "                df[fp] = df[\"standardized_smiles\"].map(mapping)\n",
    "                test_fps = np.vstack(df.loc[test_mask, fp].values)\n",
    "                train_fps = np.vstack(df.loc[train_mask, fp].values)\n",
    "                max_tcs = [max(bulk_tanimoto_similarity(test_fp, train_fps)) for test_fp in test_fps]\n",
    "                df.loc[test_mask, f\"{fold_col}_{fp}_Tc\"] = max_tcs\n",
    "\n",
    "                X_train = np.vstack(df.loc[df[fold_col] == \"Train\", fp].values)\n",
    "                y_train = df.loc[df[fold_col] == \"Train\", \"pchembl_value\"].values\n",
    "                X = np.vstack(df[fp].values)\n",
    "\n",
    "                for regressor_factory in regressor_factories:\n",
    "                    model_name, preds = process_regressor(regressor_factory, X_train, y_train, X)\n",
    "                    df[f'{fold_col}_{fp}_{model_name}'] = preds\n",
    "        df.to_csv(f\"../benchmark/data/results/{fname}\")"
   ],
   "id": "27d4c47a78878d86",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/67 [00:00<?, ?it/s]\n",
      "Processing Splits and Folds:   0%|          | 0/54 [00:00<?, ?it/s]\u001B[A/Users/manasmahale/projects/sfcv/.venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "\n",
      "Processing Splits and Folds:   2%|▏         | 1/54 [00:27<24:00, 27.17s/it]\u001B[A/Users/manasmahale/projects/sfcv/.venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "Processing Splits and Folds:   2%|▏         | 1/54 [00:29<25:42, 29.10s/it]\n",
      "Training:   0%|          | 0/67 [00:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m test_fps \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack(df\u001B[38;5;241m.\u001B[39mloc[test_mask, fp]\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m     13\u001B[0m train_fps \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack(df\u001B[38;5;241m.\u001B[39mloc[train_mask, fp]\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[0;32m---> 14\u001B[0m max_tcs \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbulk_tanimoto_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_fp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_fps\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtest_fp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtest_fps\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     15\u001B[0m df\u001B[38;5;241m.\u001B[39mloc[test_mask, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold_col\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_Tc\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m max_tcs\n\u001B[1;32m     17\u001B[0m X_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack(df\u001B[38;5;241m.\u001B[39mloc[df[fold_col] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, fp]\u001B[38;5;241m.\u001B[39mvalues)\n",
      "Cell \u001B[0;32mIn[31], line 14\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     12\u001B[0m test_fps \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack(df\u001B[38;5;241m.\u001B[39mloc[test_mask, fp]\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m     13\u001B[0m train_fps \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack(df\u001B[38;5;241m.\u001B[39mloc[train_mask, fp]\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[0;32m---> 14\u001B[0m max_tcs \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mmax\u001B[39m(\u001B[43mbulk_tanimoto_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_fp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_fps\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;28;01mfor\u001B[39;00m test_fp \u001B[38;5;129;01min\u001B[39;00m test_fps]\n\u001B[1;32m     15\u001B[0m df\u001B[38;5;241m.\u001B[39mloc[test_mask, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold_col\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_Tc\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m max_tcs\n\u001B[1;32m     17\u001B[0m X_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack(df\u001B[38;5;241m.\u001B[39mloc[df[fold_col] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, fp]\u001B[38;5;241m.\u001B[39mvalues)\n",
      "Cell \u001B[0;32mIn[22], line 2\u001B[0m, in \u001B[0;36mbulk_tanimoto_similarity\u001B[0;34m(mol_fp, list_of_fps)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mbulk_tanimoto_similarity\u001B[39m(mol_fp: np\u001B[38;5;241m.\u001B[39mndarray, list_of_fps: np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[0;32m----> 2\u001B[0m     intersection \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlist_of_fps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m&\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmol_fp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     union \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(list_of_fps \u001B[38;5;241m|\u001B[39m mol_fp, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m intersection \u001B[38;5;241m/\u001B[39m union\n",
      "File \u001B[0;32m~/projects/sfcv/.venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2313\u001B[0m, in \u001B[0;36msum\u001B[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[1;32m   2310\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m out\n\u001B[1;32m   2311\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\u001B[0;32m-> 2313\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapreduction\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2314\u001B[0m \u001B[43m                      \u001B[49m\u001B[43minitial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/sfcv/.venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88\u001B[0m, in \u001B[0;36m_wrapreduction\u001B[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001B[0m\n\u001B[1;32m     85\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     86\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m reduction(axis\u001B[38;5;241m=\u001B[39maxis, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n\u001B[0;32m---> 88\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mufunc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpasskwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:14:35.141006Z",
     "start_time": "2025-02-18T18:14:35.135700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_single_file(fname):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(f\"../benchmark/data/final/{fname}\")\n",
    "\n",
    "    # Identify fold columns\n",
    "    fold_cols = [col for col in df.columns if \"_Fold_\" in col]\n",
    "\n",
    "    for fold_col in fold_cols:\n",
    "        test_mask = df[fold_col] == \"Test\"\n",
    "        train_mask = df[fold_col] == \"Train\"\n",
    "\n",
    "        for fp, mapping in fp2map.items():\n",
    "            df[fp] = df[\"standardized_smiles\"].map(mapping)\n",
    "            test_fps = np.vstack(df.loc[test_mask, fp].values)\n",
    "            train_fps = np.vstack(df.loc[train_mask, fp].values)\n",
    "\n",
    "            max_tcs = [max(bulk_tanimoto_similarity(test_fp, train_fps)) for test_fp in test_fps]\n",
    "            df.loc[test_mask, f\"{fold_col}_{fp}_Tc\"] = max_tcs\n",
    "\n",
    "            X_train = np.vstack(df.loc[train_mask, fp].values)\n",
    "            y_train = df.loc[train_mask, \"pchembl_value\"].values\n",
    "            X_full = np.vstack(df[fp].values)\n",
    "\n",
    "            for regressor_factory in regressor_factories:\n",
    "                model_name, preds = process_regressor(regressor_factory, X_train, y_train, X_full)\n",
    "                df[f'{fold_col}_{fp}_{model_name}'] = preds\n",
    "\n",
    "    df.to_csv(f\"../benchmark/data/results/{fname}\")\n",
    "    return fname"
   ],
   "id": "868d7d4f20e6945b",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:14:44.902416Z",
     "start_time": "2025-02-18T18:14:44.899342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    files = [fname for fname in os.listdir(\"../benchmark/data/final/\") if fname.endswith(\".csv\")]\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        list(tqdm(executor.map(process_single_file, files), total=len(files), desc=\"Processing Files\"))"
   ],
   "id": "b0cc10176d27f763",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:14:47.288971Z",
     "start_time": "2025-02-18T18:14:47.082325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "d5abddfee3f1d61e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files:   0%|          | 0/67 [00:00<?, ?it/s]Process SpawnProcess-1:\n",
      "Process SpawnProcess-3:\n",
      "Process SpawnProcess-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_file' on <module '__main__' (built-in)>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_file' on <module '__main__' (built-in)>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_file' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-4:\n",
      "Processing Files:   0%|          | 0/67 [00:00<?, ?it/s]):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_file' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-5:\n",
      "\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBrokenProcessPool\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[34], line 4\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m files \u001B[38;5;241m=\u001B[39m [fname \u001B[38;5;28;01mfor\u001B[39;00m fname \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../benchmark/data/final/\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m fname\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ProcessPoolExecutor() \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[0;32m----> 4\u001B[0m     \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexecutor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_single_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mProcessing Files\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/sfcv/.venv/lib/python3.11/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1182\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[1;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py:620\u001B[0m, in \u001B[0;36m_chain_from_iterable_of_lists\u001B[0;34m(iterable)\u001B[0m\n\u001B[1;32m    614\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_chain_from_iterable_of_lists\u001B[39m(iterable):\n\u001B[1;32m    615\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    616\u001B[0m \u001B[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001B[39;00m\n\u001B[1;32m    617\u001B[0m \u001B[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001B[39;00m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;124;03m    careful not to keep references to yielded objects.\u001B[39;00m\n\u001B[1;32m    619\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43melement\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    621\u001B[0m \u001B[43m        \u001B[49m\u001B[43melement\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreverse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mwhile\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43melement\u001B[49m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:619\u001B[0m, in \u001B[0;36mExecutor.map.<locals>.result_iterator\u001B[0;34m()\u001B[0m\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m fs:\n\u001B[1;32m    617\u001B[0m     \u001B[38;5;66;03m# Careful not to keep a reference to the popped future\u001B[39;00m\n\u001B[1;32m    618\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 619\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[43m_result_or_cancel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    620\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    621\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m _result_or_cancel(fs\u001B[38;5;241m.\u001B[39mpop(), end_time \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic())\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:317\u001B[0m, in \u001B[0;36m_result_or_cancel\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    316\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 317\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfut\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    319\u001B[0m         fut\u001B[38;5;241m.\u001B[39mcancel()\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:456\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    458\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    400\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 401\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    403\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    404\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mBrokenProcessPool\u001B[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
